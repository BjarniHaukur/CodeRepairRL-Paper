\newpage
\thispagestyle{plain}
~\\
\vfill
{ \setstretch{1.1}
	\subsection*{Authors}
	Bjarni Haukur Bjarnason <bhbj@kth.se>\\ Electrical Engineering and Computer Science\\ KTH Royal Institute of Technology

	\subsection*{Place for Project} Stockholm, Sweden\\ Some place

	\subsection*{Examiner} Martin Monperrus <monperrus@kth.se>\\ Division of Theoretical Computer Science\\ KTH Royal Institute of Technology

	\subsection*{Supervisor} André Afonso Nunes Silva <andreans@kth.se>\\ Division of Theoretical Computer Science\\ KTH Royal Institute of Technology ~ }

\newpage \thispagestyle{plain} \chapter*{Abstract}

Software engineering agents have emerged as the dominant approach for automated program repair, with systems like SWE-agent, AutoCodeRover, and OpenHands achieving unprecedented success on real-world debugging tasks.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  The English abstract          %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Topic
These agents augment large language models with tools for repository navigation, code execution, and iterative refinement—capabilities essential for solving complex software engineering problems.

% Motivation
However, a critical disconnect exists between how these models are trained and deployed: while inference relies on sophisticated agent scaffolding for multi-step reasoning and environmental interaction, training typically uses static datasets of code changes without any agent capabilities.
This train-test distribution mismatch fundamentally limits model performance, as they never learn to leverage the very tools and iterative processes that define successful debugging.
Frontier labs have likely addressed this gap—systems like Anthropic's Claude Code and OpenAI's Codex demonstrate capabilities suggesting agent-based training—but their methods remain proprietary.
Similarly, while companies like OpenHands have achieved impressive results, they have not released their training procedures, leaving the open-source community without access to these critical techniques.

% Contribution
This thesis presents \textit{one of the first fully open training recipes} for coding agents, addressing a fundamental misalignment in current practice: while deployment combines models with agent scaffolds (tools, memory, action spaces), training typically optimizes models in isolation.
We introduce a reinforcement learning approach that trains the complete agent—model plus scaffold—as an integrated system.
By training models within the exact scaffolding they will use at deployment, we enable them to learn debugging strategies through environmental feedback rather than mere pattern matching.
Our work bridges the gap between closed-source frontier capabilities and open research, providing complete implementation details, training procedures, and infrastructure specifications that have previously been closely guarded industry secrets.

% Detail/Nuance
We implement this through a two-stage pipeline combining supervised fine-tuning with Group Relative Policy Optimization (GRPO), where models actively debug real repositories during training.
The key technical innovation lies in our training-inference duality: a custom integration layer enables simultaneous model training and serving, with NCCL facilitating live weight synchronization across distributed GPUs [expand: specific throughput numbers, latency implications].
Our \textit{Nano-agent} architecture provides essential bash and file operations, demonstrating that sophisticated debugging behaviors can emerge from simple interfaces when combined with reinforcement learning.

% Evidence / Secondary Contribution
Experiments on [X training instances, Y compute hours] demonstrate that interactive training yields models exhibiting sophisticated debugging behaviors: systematic hypothesis testing, incremental code modification, and test-guided exploration [specific examples needed].
On SWE-Bench-Verified, our approach achieves [X\% resolve rate], representing [Y\% improvement over baselines].
Secondary findings include positive transfer to general code generation (4\% improvement on HumanEval), emergent systematic debugging strategies, and significant computational efficiency gains through training-inference duality.

	% Weaker Result
	[Preliminary results on cross-dataset generalization / specific failure modes / computational cost analysis - expand based on actual findings]

% Narrow Impact
For automated program repair, this work establishes that interactive training is critical for developing effective debugging capabilities.
Our results suggest [specific implications for future code repair systems, importance of interactive training].

% Broad Impact
Beyond code repair, interactive RL offers a general framework for training AI systems on interactive tasks where static datasets poorly capture deployment complexity.
By demonstrating that models can learn rich environmental interactions through reinforcement learning—rather than requiring hand-crafted reasoning chains—this work points toward [future possibilities: self-improving coding assistants, autonomous software development, general interactive AI training].

\subsection*{Keywords}
Template, Thesis, Keywords .
..

\newpage
\thispagestyle{plain}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%	 The Swedish abstract         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Svenskt abstract Svensk version av abstract – samma titel på svenska som på engelska.

Skriv samma abstract på svenska.
Introducera ämnet för projektet och beskriv problemen som löses i materialet.
Presentera

\subsection*{Nyckelord} Kandidat examensarbete, .
..

\newpage
\thispagestyle{plain}
\chapter*{Acknowledgements}
I would like to express my sincere gratitude to my supervisor, André Afonso Nunes Silva, and my examiner, Martin Monperrus, for their exceptional guidance throughout this thesis.
What made this experience truly special was the rare combination of excellent supervision coupled with the freedom to steer my project in my own direction.
This trust in my judgment, even when it led to a complete pivot midway through the project, is an opportunity I deeply appreciate.

I am particularly grateful for their provision of extensive computational resources.
The trajectory of machine learning research, especially in training large language models and the nascent field of applying reinforcement learning to them, demands ever-increasing computational power.
Without access to these GPU resources, the experiments that form the core of this thesis would have remained theoretical concepts rather than empirical contributions.

I would also like to thank all the members who regularly attended the Monday meetings at ASSERT-KTH.
These sessions provided an invaluable venue for discussing emerging ideas and recent developments in machine learning.
The opportunity to engage with cutting-edge ML research in a collaborative setting has been instrumental in shaping my understanding and approach to this work.

\newpage

\input{sections/0.1-acronyms}

\newpage

\etocdepthtag.toc{mtchapter}
\etocsettagdepth{mtchapter}{subsection}
\etocsettagdepth{mtappendix}{none}
\thispagestyle{plain}
\tableofcontents

\newpage

