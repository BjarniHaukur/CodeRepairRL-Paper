\newpage
\thispagestyle{plain}
~\\
\vfill
{ \setstretch{1.1}
	\subsection*{Authors}
	Bjarni Haukur Bjarnason <bhbj@kth.se>\\ Electrical Engineering and Computer Science\\ KTH Royal Institute of Technology

	\subsection*{Place for Project} Stockholm, Sweden\\ Some place

	\subsection*{Examiner} Martin Monperrus <monperrus@kth.se>\\ Division of Theoretical Computer Science\\ KTH Royal Institute of Technology

	\subsection*{Supervisor} André Afonso Nunes Silva <andreans@kth.se>\\ Division of Theoretical Computer Science\\ KTH Royal Institute of Technology ~ }

\newpage \thispagestyle{plain} \chapter*{Abstract} Software engineering agents have emerged as the dominant approach for automated program repair, with systems like SWE-agent, OpenHands and Claude Code achieving unprecedented success on real-world software engineering tasks.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  The English abstract% Topic
These agents augment large language models with tools for repository navigation, code execution, and iterative refinement—capabilities essential for solving complex software engineering problems.

% Motivation
However, a critical disconnect exists between how these models are trained and deployed: while deployment requires dynamic, multi-step interactions with complex software environments, training typically relies on static datasets of isolated code changes that capture none of this interactive complexity.
This train-test distribution mismatch fundamentally limits model performance, as they never learn to leverage the very tools and iterative processes that enable successful debugging.
Frontier labs have likely addressed this gap—systems like Anthropic's Claude Code and OpenAI's Codex demonstrate capabilities suggesting agent-based training—but their methods remain proprietary.
Similarly, while companies like OpenHands have achieved impressive results, they have not released their training procedures, leaving the open-source community without access to these critical techniques.

% Contribution
\todoinline{Easy to make specialists, hard to make generalists, frontier labs probably have a wide range of RL tasks}
This thesis presents \textit{one of the first fully open training recipes} for coding agents, addressing a fundamental misalignment in current practice: while deployment combines models with agent scaffolds (tools, memory, action spaces), training typically optimizes models in isolation.
We introduce a \ac{RL} approach that trains the \ac{LLM} within its deployment scaffold, enabling the model to learn optimal tool usage and debugging strategies through environmental interaction.
By training models within the exact scaffolding they will use at deployment, we enable them to learn debugging strategies through environmental feedback rather than mere pattern matching.
Our work attempts to bridge the gap between closed-source frontier capabilities and open research, providing complete implementation details, training procedures and infrastructure specifications.

% Detail/Nuance
We implement this through \ac{GRPO}~\cite{shao2024deepseekmathpushinglimitsmathematical}, where models actively debug real repositories during training.
The key technical innovation lies in our training-inference duality: a custom integration layer enables simultaneous model training and serving, with \ac{NCCL} facilitating live weight synchronization across distributed \acsp{GPU} [expand: specific throughput numbers, latency implications].
Our \textit{Nano-agent} architecture provides essential bash and file operations, demonstrating that sophisticated debugging behaviors can emerge from simple interfaces when combined with \ac{RL}.

% Evidence / Secondary Contribution
Experiments on [X training instances, Y compute hours] demonstrate that interactive training yields models exhibiting sophisticated debugging behaviors: systematic hypothesis testing, incremental code modification, and test-guided exploration [specific examples needed].
On \ac{SWE-Bench-Verified}, our approach achieves [X\% resolve rate], representing [Y\% improvement over baselines].
Secondary findings include positive transfer to general code generation (4\% improvement on HumanEval), emergent systematic debugging strategies, and significant computational efficiency gains through training-inference duality.

	% Weaker Result
	[Preliminary results on cross-dataset generalization / specific failure modes / computational cost analysis - expand based on actual findings]

% Narrow Impact
For automated program repair, this work establishes that interactive training is critical for developing effective debugging capabilities.
Our results suggest [specific implications for future code repair systems, importance of interactive training].

% Broad Impact
Beyond code repair, \ac{RL} offers a general framework for training \ac{AI} systems on interactive tasks where static datasets poorly capture deployment complexity.
By demonstrating that models can learn rich environmental interactions through \ac{RL}—rather than requiring hand-crafted reasoning chains—this work points toward [future possibilities: self-improving coding assistants, autonomous software development, general interactive \ac{AI} training].

\subsection*{Keywords}
Template, Thesis, Keywords .
..

\newpage
\thispagestyle{plain}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%	 The Swedish abstract         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Svenskt abstract Svensk version av abstract – samma titel på svenska som på engelska.

Skriv samma abstract på svenska.
Introducera ämnet för projektet och beskriv problemen som löses i materialet.
Presentera

\subsection*{Nyckelord} Kandidat examensarbete, .
..

\newpage
\thispagestyle{plain}
\chapter*{Acknowledgements}
I would like to express my sincere gratitude to my supervisor, André Afonso Nunes Silva, and my examiner, Martin Monperrus, for their exceptional guidance throughout this thesis.
What made this experience truly special was the rare combination of excellent supervision coupled with the freedom to steer my project in my own direction.
This trust in my judgment, even when it led to a complete pivot midway through the project, is an opportunity I deeply appreciate.

I am particularly grateful for their provision of extensive computational resources.
The trajectory of \ac{ML} research, especially in training large language models and the nascent field of applying \ac{RL} to them, demands ever-increasing computational power.
Without access to these \ac{GPU} resources, the experiments that form the core of this thesis would have remained theoretical concepts rather than empirical contributions.

\todoinline{My friends in the program}

I would also like to thank all the members who regularly attended the Monday meetings at ASSERT-KTH.
These sessions provided an invaluable venue for discussing emerging ideas and recent developments in \ac{ML}.
The opportunity to engage with cutting-edge \ac{ML} research in a collaborative setting has been instrumental in shaping my understanding and approach to this work.

\newpage

\input{sections/0.1-acronyms}

\newpage

\etocdepthtag.toc{mtchapter}
\etocsettagdepth{mtchapter}{subsection}
\etocsettagdepth{mtappendix}{none}
\thispagestyle{plain}
\tableofcontents

\newpage

