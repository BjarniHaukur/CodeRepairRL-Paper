@article{alphaZero2018,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@misc{openHands2024,
  title={OpenHands: An Open Platform for AI Software Developers as Generalist Agents},
  author={Wang, Xingyao and Chen, Boxuan and Li, Yufan and Zhang, Bowen and Liu, Zhengyang and Gao, Cheng and Huang, Yue and Li, Guanzhi and Zhang, Nan and Xu, Mengnan and others},
  journal={arXiv preprint arXiv:2407.16741},
  year={2024}
}

@misc{aider2024,
  title={AI pair programming in your terminal },
  author={Aider-AI},
  year={2024},
  howpublished = {\url{https://github.com/Aider-AI/aider}},
}

@article{sutton2019bitter,
  title={The Bitter Lesson},
  author={Sutton, Richard},
  journal={Incomplete Ideas (blog)},
  year={2019},
  note={Available at: http://www.incompleteideas.net/IncIdeas/BitterLesson.html}
}

@misc{shao2024deepseekmathpushinglimitsmathematical,
      title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}, 
      author={Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Xiao Bi and Haowei Zhang and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
      year={2024},
      eprint={2402.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.03300}, 
}

@article{deepseekr1_2025,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={DeepSeek-AI},
  journal={arXiv:2501.12948},
  year={2025}
}

@misc{qwen2024,
  title={Qwen Technical Report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv:2309.16609},
  year={2024}
}

@article{repairllama2023,
  title={RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair},
  author={Silva, Andr{\'e} and Fang, Sen and Monperrus, Martin},
  journal={arXiv preprint arXiv:2312.15698},
  year={2023}
}

@article{llama3swerl2025,
  title={Teaching Code LLMs to Repository-Level Bug Fixing with Reinforcement Learning},
  author={He, Yue and Wang, Zhewei},
  journal={arXiv preprint arXiv:2502.18449},
  year={2025}
}

@article{deepseekr1_2025,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={DeepSeek-AI},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{vllm2023,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E and Zhang, Hao and Stoica, Ion},
  journal={arXiv preprint arXiv:2309.06180},
  year={2023}
}

@inproceedings{humaneval2021,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  booktitle={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{lora2021,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@misc{trl,
  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
  title = {TRL: Transformer Reinforcement Learning},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/trl}}
}

@misc{schulman2017proximalpolicyoptimizationalgorithms,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.06347}, 
}

@article{rlhf2022,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@misc{nccl2018,
  title={NCCL: NVIDIA Collective Communications Library},
  author={NVIDIA Corporation},
  year={2018},
  howpublished={\url{https://developer.nvidia.com/nccl}}
}

@article{deepspeed2020,
  title={ZeRO: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  journal={arXiv preprint arXiv:1910.02054},
  year={2020}
}

@article{gradientcheckpointing2016,
  title={Training deep nets with sublinear memory cost},
  author={Chen, Tianqi and Xu, Bing and Zhang, Chiyuan and Guestrin, Carlos},
  journal={arXiv preprint arXiv:1604.06174},
  year={2016}
}

@article{flashattention2022,
  title={FlashAttention: Fast and memory-efficient exact attention with IO-awareness},
  author={Dao, Tri and Fu, Daniel Y and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2205.14135},
  year={2022}
}

@misc{swe_bench,
    title={SWE-bench: Can Language Models Resolve Real-World GitHub Issues?}, 
    author={Carlos E. Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik Narasimhan},
    year={2024},
    eprint={2310.06770},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2310.06770}, 
}

@article{multiswebench2024,
  title={Multi-SWE-bench: Are LLMs Proficient Problem Solvers beyond Python?},
  author={Wang, Albert and Singh, Inderjeet and Blanco-Cuaresma, Sergi},
  journal={arXiv preprint arXiv:2408.14354},
  year={2024}
}

@article{sweBenchVerified2024,
  title={SWE-bench-verified: A Curated Subset of Real-world Software Engineering Problems},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander},
  journal={arXiv preprint arXiv:2403.11506},
  year={2024}
}

@article{swegym2024,
  title={SWE-Gym: Practical Software Engineering},
  author={Jimenez, Carlos E and Bouzenia, Didem and Yang, John},
  journal={arXiv preprint arXiv:2410.23743},
  year={2024}
}

@article{r2e_gym2024,
  title={R2E: Turning Any GitHub Repository into a Programming Agent Environment},
  author={Wu, Yuntao and Li, Zhewei and Zhang, Junyi and Paullada, Mike and Hong, Haohan and Qi, Zhuowen},
  journal={arXiv preprint arXiv:2406.18973},
  year={2024}
}


@article{bitterLesson2019,
  title={The Bitter Lesson},
  author={Sutton, Richard S},
  year={2019},
  journal={Incomplete Ideas (blog)},
  note={Available at: http://www.incompleteideas.net/IncIdeas/BitterLesson.html}
}

@article{codeRL2022,
  title={CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning},
  author={Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven C.H.},
  journal={arXiv preprint arXiv:2207.01780},
  year={2022}
}

2021,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}


@misc{cognition2024,
  title={Devin: The First AI Software Engineer},
  author={Cognition},
  year={2024},
  howpublished={\url{https://www.cognition-labs.com/introducing-devin}}
}

@misc{copilotWorkspace2024,
  title={GitHub Copilot Workspace},
  author={GitHub},
  year={2024},
  howpublished={\url{https://githubnext.com/projects/copilot-workspace}}
}

@misc{cursor2024,
  title={Cursor: The AI Code Editor},
  author={Cursor Team},
  year={2024},
  howpublished={\url{https://cursor.sh}}
}

@article{defects4j2014,
  title={Defects4J: A Database of Existing Faults to Enable Controlled Testing Studies for Java Programs},
  author={Just, René and Jalali, Darioush and Ernst, Michael D},
  journal={Proceedings of the 2014 International Symposium on Software Testing and Analysis},
  pages={437--440},
  year={2014}
}

@article{defects4j2020,
  title={The Defects4J Database and Framework for Research in Automated Debugging},
  author={Just, René and Jalali, Darioush and Inozemtseva, Laura and Ernst, Michael D and Holmes, Reid and Fraser, Gordon},
  journal={Software Testing, Verification and Reliability},
  volume={30},
  number={6},
  year={2020}
}

@article{diffGeneration2024,
  title={Teaching Language Models to Generate Better Diffs},
  author={Wu, Zeyu and Li, Yudong and Chen, Qiushi and Zhang, Zhiwei},
  journal={arXiv preprint arXiv:2402.18192},
  year={2024}
}

@article{diverseSampling2024,
  title={Diverse Sampling for Better Code Generation},
  author={Wang, Yue and Le, Hung and Gotmare, Akhilesh Deepak and Bui, Nghi D.Q. and Li, Junnan and Hoi, Steven C.H.},
  journal={arXiv preprint arXiv:2206.07650},
  year={2024}
}

@article{gitbugJava2023,
  title={GitBug-Java: A Reproducible Benchmark for Java Program Repair},
  author={Wang, Yuxiao and Li, Chunqiu Steven and Joty, Shafiq},
  journal={arXiv preprint arXiv:2309.11044},
  year={2023}
}

@article{multiSWEBench2024,
  title={Multi-SWE-bench: Multi-language Software Engineering Evaluation},
  author={Wang, Albert and Singh, Inderjeet and Blanco-Cuaresma, Sergi},
  journal={arXiv preprint arXiv:2408.14354},
  year={2024}
}

@misc{openAI_o1_2024,
  title={Learning to Reason with LLMs},
  author={OpenAI},
  year={2024},
  howpublished={\url{https://openai.com/o1}}
}

@article{openhands2024,
  title={OpenHands: An Open Platform for AI Software Developers as Generalist Agents},
  author={Wang, Xingyao and Chen, Boxuan and Li, Yufan and Zhang, Bowen and Liu, Zhengyang and Gao, Cheng and Huang, Yue and Li, Guanzhi and Zhang, Nan and Xu, Mengnan and others},
  journal={arXiv preprint arXiv:2407.16741},
  year={2024}
}

@article{repairllama2024,
  title={RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair},
  author={Silva, André and Fang, Sen and Monperrus, Martin},
  journal={arXiv preprint arXiv:2312.15698},
  year={2024}
}

@article{sequencer2019,
  title={Sequencer: Sequence-to-Sequence Learning for End-to-End Program Repair},
  author={Chen, Zimin and Kommrusch, Steve and Tufano, Michele and Poshyvanyk, Denys and Monperrus, Martin},
  journal={IEEE Transactions on Software Engineering},
  volume={47},
  number={9},
  pages={1943--1959},
  year={2019}
}

@article{sweAgent2024,
  title={SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering},
  author={Yang, John and Jimenez, Carlos E and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2405.15793},
  year={2024}
}

@misc{claude4_2025,
  title={Claude 4: Building a New Era of AI Assistant Capabilities},
  author={Anthropic},
  year={2025},
  howpublished={\url{https://www-cdn.anthropic.com/07b2a3f9902ee19fe39a36ca638e5ae987bc64dd.pdf}},
  note={Technical report detailing Claude 4's performance on SWE-Bench-Verified and other benchmarks}
}

@misc{kimiK2_2025,
  title={Kimi-K2 Technical Report},
  author={MoonshotAI},
  year={2025},
  howpublished={\url{https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf}},
  note={Open weight model technical documentation}
}

@misc{qwen3coder_blog_2025,
  title={Qwen3-Coder: Agentic Coding in the World},
  author={Qwen Team},
  year={2025},
  howpublished={\url{https://qwenlm.github.io/blog/qwen3-coder/}},
  note={Blog post introducing Qwen3-Coder capabilities}
}

@article{qwen3_2025,
  title={Qwen3 Technical Report},
  author={Qwen Team},
  journal={arXiv preprint arXiv:2505.09388},
  year={2025}
}

@misc{zheng2025groupsequencepolicyoptimization,
      title={Group Sequence Policy Optimization}, 
      author={Chujie Zheng and Shixuan Liu and Mingze Li and Xiong-Hui Chen and Bowen Yu and Chang Gao and Kai Dang and Yuqiong Liu and Rui Men and An Yang and Jingren Zhou and Junyang Lin},
      year={2025},
      eprint={2507.18071},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2507.18071}, 
}